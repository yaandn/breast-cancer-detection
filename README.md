<h1>ğŸ©º Breast Cancer Detector â€” YOLO11</h1>
<p>Detector de anomalias em mamografias utilizando Deep Learning</p>

<p>Este projeto implementa um modelo <strong>YOLO11</strong> treinado para identificar possÃ­veis tumores <strong>malignos</strong>, <strong>benignos</strong> ou padrÃµes <strong>normais</strong> em mamografias. O pipeline utiliza mÃ¡scaras para gerar labels, divide as imagens em classes e aplica <strong>augmentations</strong> para aumentar a robustez do modelo em cenÃ¡rios reais.</p>

<hr />

<h2>ğŸ“ Estrutura do Projeto</h2>

<pre>
breast-cancer-detector/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data.yaml
â”‚   â””â”€â”€ datasets/
â”‚       â”œâ”€â”€ images/
â”‚       â”‚   â”œâ”€â”€ train/
â”‚       â”‚   â””â”€â”€ val/
â”‚       â”œâ”€â”€ labels/
â”‚       â”‚   â”œâ”€â”€ train/
â”‚       â”‚   â””â”€â”€ val/
â”‚       â””â”€â”€ classes.txt
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ yolo11.pt
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ detector_tumores.py
â”‚   â”œâ”€â”€ augment.py
â”‚   â”œâ”€â”€ prepare_dataset.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ results/
â”‚   â””â”€â”€ training/
â”‚       â”œâ”€â”€ weights/
â”‚       â”œâ”€â”€ results.csv
â”‚       â”œâ”€â”€ confusion_matrix.png
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ README.md
</pre>

<hr />

<h2>ğŸ¯ Objetivo do Projeto</h2>

<ul>
  <li>âœ” Detectar lesÃµes suspeitas em mamografias</li>
  <li>âœ” Diferenciar <strong>normal</strong>, <strong>benigno</strong> e <strong>maligno</strong></li>
  <li>âœ” Auxiliar pesquisadores e profissionais na anÃ¡lise das imagens</li>
  <li>âœ” Aumentar a precisÃ£o em imagens claras ou fora do padrÃ£o</li>
</ul>

<hr />

<h2>ğŸ§© Classes Utilizadas</h2>

<table>
  <thead>
    <tr>
      <th>ID</th>
      <th>Classe</th>
    </tr>
  </thead>
  <tbody>
    <tr><td>0</td><td>Normal</td></tr>
    <tr><td>1</td><td>Benigno</td></tr>
    <tr><td>2</td><td>Maligno</td></tr>
  </tbody>
</table>

<p>Definidas em:</p>
<ul>
  <li><code>data/data.yaml</code></li>
  <li><code>data/datasets/classes.txt</code></li>
</ul>

<hr />

<h2>ğŸ—‚ Dataset</h2>

<p>OrganizaÃ§Ã£o no formato padrÃ£o YOLO:</p>

<pre>
images/
   train/
   val/
labels/
   train/
   val/
</pre>

<p>As labels foram geradas automaticamente a partir das mÃ¡scaras com:</p>
<code>scripts/prepare_dataset.py</code>

<hr />

<h2>ğŸ”„ Data Augmentation</h2>

<p>Para melhorar desempenho e balancear classes, foram usadas:</p>
<ul>
  <li>RotaÃ§Ã£o</li>
  <li>Flip horizontal/vertical</li>
  <li>Ajuste de brilho</li>
  <li>Ajuste de contraste</li>
  <li>RuÃ­do</li>
  <li>Crop aleatÃ³rio</li>
</ul>

<p>Script:</p>
<code>scripts/augment.py</code>

<hr />

<h2>ğŸ¤– Treinamento</h2>

<p>Comando utilizado:</p>

<pre>
yolo train \
    model=models/yolo11.pt \
    data=data/data.yaml \
    epochs=80 \
    imgsz=640 \
    batch=4 \
    device=0
</pre>

<p>Resultados salvos em:</p>
<code>results/training/</code>

<ul>
  <li>Pesos finais</li>
  <li>Matriz de confusÃ£o</li>
  <li>Curvas P/R</li>
  <li>Curva F1</li>
  <li>PrediÃ§Ãµes de validaÃ§Ã£o</li>
  <li>CSV com mÃ©tricas</li>
</ul>

<hr />

<h2>ğŸ“ˆ Resultados Gerados</h2>

<p>YOLO gera automaticamente:</p>
<ul>
  <li>ğŸ“Š Confusion Matrix</li>
  <li>ğŸ“Š Normalized Confusion Matrix</li>
  <li>ğŸ“ˆ Precision Ã— Recall</li>
  <li>ğŸ“ˆ F1 Curve</li>
  <li>ğŸ“‰ Loss Curve</li>
  <li>ğŸ–¼ Batch Predictions</li>
</ul>

<p>Local:</p>
<code>results/training/</code>

<hr />

<h2>ğŸ” InferÃªncia</h2>

<p>Script:</p>
<code>scripts/detector_tumores.py</code>

<p>Uso:</p>

<pre>
python3 scripts/detector_tumores.py --image caminho/da/imagem.jpg
</pre>

<p>O script:</p>
<ul>
  <li>Carrega o modelo</li>
  <li>Executa a prediÃ§Ã£o</li>
  <li>Salva a imagem anotada</li>
  <li>Exporta coordenadas</li>
  <li>Gera relatÃ³rio JSON</li>
</ul>

<hr />

<h2>ğŸ§ª Exemplo em Python</h2>

<pre>
from ultralytics import YOLO

model = YOLO("models/yolo11.pt")
results = model("exemplo.jpg")
results[0].show()
</pre>

<hr />

<h2>ğŸ“„ Arquivo data.yaml</h2>

<pre>
train: data/datasets/images/train
val: data/datasets/images/val

nc: 3
names: ["normal", "benigno", "maligno"]
</pre>

